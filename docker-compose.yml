version: "3.1"

services:
  flowise:
    image: elestio/flowiseai
    restart: always
    environment:
      - PORT=3000
      # - FLOWISE_USERNAME=${USERNAME}
      # - FLOWISE_PASSWORD=${ADMIN_PASSWORD}
    ports:
      - "127.0.0.1:3000:3000"
    volumes:
      - ./data/flowise/.flowise:/root/.flowise

  api:
    image: localai/localai:latest-aio-cpu
    # For a specific version:
    # image: localai/localai:v2.20.1-aio-cpu
    # For Nvidia GPUs decomment one of the following (cuda11 or cuda12):
    # image: localai/localai:v2.20.1-aio-gpu-nvidia-cuda-11
    # image: localai/localai:v2.20.1-aio-gpu-nvidia-cuda-12
    # image: localai/localai:latest-aio-gpu-nvidia-cuda-11
    # image: localai/localai:latest-aio-gpu-nvidia-cuda-12
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/readyz"]
      interval: 1m
      timeout: 20m
      retries: 5
    ports:
      - 127.0.0.1:8080:8080
    environment:
      - DEBUG=true
      # ...
    volumes:
      - ./data/localai/models:/build/models:cached


# auth !$pB^4Na9LEeoZRc